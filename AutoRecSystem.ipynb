{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13238084",
   "metadata": {},
   "source": [
    "# Section 6: Project #1\n",
    "## 딥러닝 기반의 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5082cf",
   "metadata": {},
   "source": [
    "빅데이터 분석 기술의 발전에 따라 활동이나 선호도를 개인별로 추정할 수 있는 방법들이 개발되고 있습니다.  \n",
    "<br>\n",
    "이런 개인화 서비스 영역에 큰 비중을 차지하고 있는 추천 시스템을 이번 프로젝트 주제로 삼게 되었고  \n",
    "특히 여러가지 모델을 통해 기능을 구현하면서 모델들 간에 어떤 차이가 있는지 파악하고자 했습니다.  \n",
    "동시에 딥러닝 모델을 적용한다면 성능을 올릴 수 있을지 확인해보고자 했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b858a65",
   "metadata": {},
   "source": [
    "### 1) Data Description\n",
    "#### MovieLens Dataset\n",
    "```\n",
    "It contains 20000263 ratings and 465564 tag applications across 27278 movies. \n",
    "These data were created by 138493 users between January 09, 1995 and March 31, 2015. \n",
    "This dataset was generated on October 17, 2016.\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "146e863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000263, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp\n",
       "0       1        2     3.5  2005-04-02 23:53:47\n",
       "1       1       29     3.5  2005-04-02 23:31:16\n",
       "2       1       32     3.5  2005-04-02 23:33:39\n",
       "3       1       47     3.5  2005-04-02 23:32:07\n",
       "4       1       50     3.5  2005-04-02 23:29:40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('dataset/Movielens_Dataset/rating.csv')\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93519271",
   "metadata": {},
   "source": [
    "### 2) Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c171975",
   "metadata": {},
   "source": [
    "2-1) 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1086bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp 칼럼 제거\n",
    "dataset = dataset[['userId', 'movieId', 'rating']]\n",
    "# 중복값, 결측치 제거\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549a7059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>118205</th>\n",
       "      <th>8405</th>\n",
       "      <th>82418</th>\n",
       "      <th>121535</th>\n",
       "      <th>125794</th>\n",
       "      <th>74142</th>\n",
       "      <th>34576</th>\n",
       "      <th>131904</th>\n",
       "      <th>83090</th>\n",
       "      <th>59477</th>\n",
       "      <th>...</th>\n",
       "      <th>12608</th>\n",
       "      <th>75769</th>\n",
       "      <th>75755</th>\n",
       "      <th>3555</th>\n",
       "      <th>24457</th>\n",
       "      <th>89305</th>\n",
       "      <th>110463</th>\n",
       "      <th>96990</th>\n",
       "      <th>134747</th>\n",
       "      <th>6526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9254.000000</td>\n",
       "      <td>7515.000000</td>\n",
       "      <td>5646.000000</td>\n",
       "      <td>5520.000000</td>\n",
       "      <td>5491.000000</td>\n",
       "      <td>5447.000000</td>\n",
       "      <td>5356.000000</td>\n",
       "      <td>5330.000000</td>\n",
       "      <td>5169.000000</td>\n",
       "      <td>4988.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.279069</td>\n",
       "      <td>3.208317</td>\n",
       "      <td>3.516915</td>\n",
       "      <td>2.793116</td>\n",
       "      <td>3.762976</td>\n",
       "      <td>1.577474</td>\n",
       "      <td>3.011669</td>\n",
       "      <td>3.248874</td>\n",
       "      <td>2.404914</td>\n",
       "      <td>2.455092</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.875</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.825</td>\n",
       "      <td>2.975</td>\n",
       "      <td>3.275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 138493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId       118205       8405         82418        121535       125794  \\\n",
       "count   9254.000000  7515.000000  5646.000000  5520.000000  5491.000000   \n",
       "mean       3.279069     3.208317     3.516915     2.793116     3.762976   \n",
       "\n",
       "userId       74142        34576        131904       83090        59477   ...  \\\n",
       "count   5447.000000  5356.000000  5330.000000  5169.000000  4988.000000  ...   \n",
       "mean       1.577474     3.011669     3.248874     2.404914     2.455092  ...   \n",
       "\n",
       "userId  12608   75769   75755   3555    24457   89305   110463  96990   \\\n",
       "count     20.0    20.0  20.000   20.00    20.0   20.00   20.00  20.000   \n",
       "mean       2.7     3.4   3.875    3.85     2.9    3.75    3.75   3.825   \n",
       "\n",
       "userId  134747  6526    \n",
       "count   20.000  20.000  \n",
       "mean     2.975   3.275  \n",
       "\n",
       "[2 rows x 138493 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('userId')['rating'].agg(['count', 'mean'])\\\n",
    "        .sort_values(by='count', ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6efb57da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>296</th>\n",
       "      <th>356</th>\n",
       "      <th>318</th>\n",
       "      <th>593</th>\n",
       "      <th>480</th>\n",
       "      <th>260</th>\n",
       "      <th>110</th>\n",
       "      <th>589</th>\n",
       "      <th>2571</th>\n",
       "      <th>527</th>\n",
       "      <th>...</th>\n",
       "      <th>110794</th>\n",
       "      <th>110798</th>\n",
       "      <th>110800</th>\n",
       "      <th>110802</th>\n",
       "      <th>110805</th>\n",
       "      <th>110807</th>\n",
       "      <th>110811</th>\n",
       "      <th>78984</th>\n",
       "      <th>110818</th>\n",
       "      <th>131262</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67310.000000</td>\n",
       "      <td>66172.000</td>\n",
       "      <td>63366.00000</td>\n",
       "      <td>63299.000000</td>\n",
       "      <td>59715.000000</td>\n",
       "      <td>54502.000000</td>\n",
       "      <td>53769.000000</td>\n",
       "      <td>52244.000000</td>\n",
       "      <td>51334.000000</td>\n",
       "      <td>50054.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.174231</td>\n",
       "      <td>4.029</td>\n",
       "      <td>4.44699</td>\n",
       "      <td>4.177057</td>\n",
       "      <td>3.664741</td>\n",
       "      <td>4.190672</td>\n",
       "      <td>4.042534</td>\n",
       "      <td>3.931954</td>\n",
       "      <td>4.187186</td>\n",
       "      <td>4.310175</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26744 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId        296        356          318           593           480     \\\n",
       "count    67310.000000  66172.000  63366.00000  63299.000000  59715.000000   \n",
       "mean         4.174231      4.029      4.44699      4.177057      3.664741   \n",
       "\n",
       "movieId        260           110           589           2571          527     \\\n",
       "count    54502.000000  53769.000000  52244.000000  51334.000000  50054.000000   \n",
       "mean         4.190672      4.042534      3.931954      4.187186      4.310175   \n",
       "\n",
       "movieId  ...  110794  110798  110800  110802  110805  110807  110811  78984   \\\n",
       "count    ...     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
       "mean     ...     3.5     4.5     0.5     0.5     2.5     4.0     1.5     2.0   \n",
       "\n",
       "movieId  110818  131262  \n",
       "count       1.0     1.0  \n",
       "mean        1.0     4.0  \n",
       "\n",
       "[2 rows x 26744 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('movieId')['rating'].agg(['count', 'mean'])\\\n",
    "        .sort_values(by='count', ascending=False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6786428e",
   "metadata": {},
   "source": [
    "### 3) ML modeling\n",
    "\n",
    "기본적으로 추천시스템을 구현하는 방식은 여러 가지가 존재합니다.  \n",
    "- 각각 영화의 감독, 주연배우, 장르, 출시 시기 등의 요소들을 기반으로 선호도를 예측하는 컨텐츠 기반 필터링\n",
    "- 이용자들 간 비슷한 선호를 가진 사람을 통해 선호도를 예측하는 협력 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed52c50",
   "metadata": {},
   "source": [
    "이 프로젝트에서는 '개인화'라는 키워드에 초점을 맞추고 있기 때문에 협력 필터링을 구현했습니다.\n",
    "<br><br>\n",
    "실제로 시도하는 모델은 다음과 같습니다.\n",
    "- Baseline: ALS (Alternative Least Square) 모델\n",
    "- 특이값분해 SVD (Singular Value Decomposition) 모델\n",
    "- Deep learning 구조 기반의 AutoEncoder 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213517b",
   "metadata": {},
   "source": [
    "세 가지 모델은 모두 구조적으로 행렬분해 (Matrix Factorization)에 기반을 두고 있습니다.  \n",
    "비슷한 방식으로 작동하는 모델이기 때문에 비교가 용이할 것이라 생각했습니다.\n",
    "<br><br>\n",
    "행렬 분해의 작동 과정을 정리하자면  \n",
    "1) 차원 축소를 통해 잠재특성 (latent feature) 추출  \n",
    "2) 잠재특성을 기반으로 원래의 행렬을 예측  \n",
    "3) 예측된 수치와 실제 수치 간의 차이를 최소화하는 방식으로 최적화\n",
    "<br><br>\n",
    "이 프로젝트에서는 python surprise library를 통해서 ALS와 SVD 모델을 구현했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72038262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import Reader, Dataset, BaselineOnly, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split, KFold\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(dataset[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, validset = train_test_split(data, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcfc8ac1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 0.8587\n",
      "FCP:  0.7095\n"
     ]
    }
   ],
   "source": [
    "# Alternative Least Square\n",
    "\n",
    "bsl_options = {'method':'als', 'n_epochs':15}\n",
    "\n",
    "als_algo = BaselineOnly(bsl_options=bsl_options)\n",
    "als_algo.fit(trainset)\n",
    "als_predict = als_algo.test(validset)\n",
    "\n",
    "als_score = accuracy.rmse(als_predict)\n",
    "als_fcp = accuracy.fcp(als_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1be030dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7929\n",
      "FCP:  0.7509\n"
     ]
    }
   ],
   "source": [
    "# Singular Value Decomposition\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "svd_predict = algo.test(validset)\n",
    "\n",
    "svd_score = accuracy.rmse(svd_predict)\n",
    "svd_fcp = accuracy.fcp(svd_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a09d41",
   "metadata": {},
   "source": [
    "### 4) DL Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80052d",
   "metadata": {},
   "source": [
    "협력 필터링의 행렬분해 구조를 구현하려면 잠재특성 (Latent Feature)를 추출해야 합니다.\n",
    "<br>\n",
    "AutoEncoder 모델을 적용하여 추천 시스템을 구현했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b68639",
   "metadata": {},
   "source": [
    "작성한 함수는 NVIDIA 사에서 공개한 'DeepRecommender' model을 참고해서 작성했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8305c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NVIDIA Deep Recommender (AutoEncoder)\n",
    "# Copyright (c) 2017 NVIDIA Corporation\n",
    "## reco_encoder.model\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as weight_init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def activation(input, kind):\n",
    "    return F.selu(input)\n",
    "\n",
    "def MSEloss(inputs, targets, size_average=True):\n",
    "    mask = targets != 0\n",
    "    num_ratings = torch.sum(mask.float())\n",
    "    criterion = nn.MSELoss(reduction='sum' if not size_average else 'mean')\n",
    "    return criterion(inputs * mask.float(), targets),\\\n",
    "           Variable(torch.Tensor([1.0])) if size_average else num_ratings\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, layer_sizes, nl_type='selu', is_constrained=True, dp_drop_prob=0.0, last_layer_activations=True):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self._dp_drop_prob = dp_drop_prob\n",
    "        self._last_layer_activations = last_layer_activations\n",
    "        if dp_drop_prob>0:\n",
    "            self.drop = nn.Dropout(dp_drop_prob)\n",
    "        self._last = len(layer_sizes) - 2\n",
    "        self._nl_type = nl_type\n",
    "        self.encode_w = nn.ParameterList(\n",
    "            [nn.Parameter(torch.rand(layer_sizes[i+1], layer_sizes[i])) for i in range(len(layer_sizes)-1)])\n",
    "        for ind, w in enumerate(self.encode_w):\n",
    "            weight_init.xavier_uniform_(w)\n",
    "        self.encode_b = nn.ParameterList(\n",
    "        [nn.Parameter(torch.zeros(layer_sizes[i+1])) for i in range(len(layer_sizes)-1)])\n",
    "        reversed_enc_layers = list(reversed(layer_sizes))\n",
    "        self.is_constrained = is_constrained\n",
    "        \n",
    "        if not is_constrained:\n",
    "            self.decode_w = nn.ParameterList(\n",
    "            [nn.Parameter(torch.zeros(reversed_enc_layers[i+1])) for i in range(len(reversed_enc_layers)-1)])\n",
    "            for ind, w in enumerate(self.decode_w):\n",
    "                weight_init.xavier_uniform(w)\n",
    "        self.decode_b = nn.ParameterList(\n",
    "        [nn.Parameter(torch.zeros(reversed_enc_layers[i+1])) for i in range(len(reversed_enc_layers)-1)])\n",
    "        print('Encoder pass:')\n",
    "        for ind, w in enumerate(self.encode_w):\n",
    "            print(w.data.size())\n",
    "            print(self.encode_b[ind].size())\n",
    "    \n",
    "    def encode(self, x):\n",
    "        for ind, w in enumerate(self.encode_w):\n",
    "            x = activation(input=F.linear(input=x, weight=w, bias=self.encode_b[ind]), kind=self._nl_type)\n",
    "        if self._dp_drop_prob > 0:\n",
    "            x = self.drop(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z):\n",
    "        if self.is_constrained:\n",
    "            for ind, w in enumerate(list(reversed(self.encode_w))):\n",
    "                z = activation(input=F.linear(input=z, weight=w.transpose(0, 1), bias=self.decode_b[ind]),\n",
    "                              kind=self._nl_type if ind!=self._last or self._last_layer_activations else 'none')\n",
    "        else:\n",
    "            for ind, w in enumerate(self.decode_w):\n",
    "                z = activation(input=F.linear(input=z, weight=w, bias=self.decode_b[ind]),\n",
    "                              kind=self._nl_type if ind!=self._last or self._last_layer_activations else 'none')\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82ed4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Layer Classes\n",
    "## reco_encoder.data.input_layer\n",
    "\n",
    "from os import listdir, path\n",
    "from random import shuffle\n",
    "from pathlib import Path\n",
    "\n",
    "class UserItemRecDataProvider:\n",
    "    def __init__(self, params, user_id_map=None, item_id_map=None):\n",
    "        self._params = params\n",
    "        self._data_dir = self.params['data_dir']\n",
    "        self._extension = \".txt\" if 'extension' not in self.params else self.params['extension']\n",
    "        self._i_id = 0 if 'itemIdInd' not in self.params else self.params['itemIdInd']\n",
    "        self._u_id = 1 if 'userIdInd' not in self.params else self.params['userIdInd']\n",
    "        self._r_id = 2 if 'ratingInd' not in self.params else self.params['ratingInd']\n",
    "        self._major = 'items' if 'major' not in self.params else self.params['major']\n",
    "        if not (self._major == 'items' or self._major=='users'):\n",
    "            raise ValueError('Major must be \"users\" or \"items\", but got {}'.format(self._major))\n",
    "        self._major_ind = self._i_id if self._major == 'items' else self._u_id\n",
    "        self._minor_ind = self._u_id if self._major == 'items' else self._i_id\n",
    "        self._delimiter = '\\t' if 'delimiter' not in self.params else self.params['delimiter']\n",
    "        if user_id_map is None or item_id_map is None:\n",
    "            self._build_maps()\n",
    "        else:\n",
    "            self._user_id_map = user_id_map\n",
    "            self._item_id_map = item_id_map\n",
    "        major_map = self._item_id_map if self._major=='items' else self._user_id_map\n",
    "        minor_map = self._user_id_map if self._major=='items' else self._item_id_map\n",
    "        self._vector_dim = len(minor_map)\n",
    "        src_files = [path.join(self._data_dir, f)\n",
    "                    for f in listdir(self._data_dir)\n",
    "                    if path.isfile(path.join(self._data_dir, f)) and f.endswith(self._extension)]\n",
    "        self._batch_size = 32\n",
    "        \n",
    "        self.data = dict()\n",
    "        for source_file in src_files:\n",
    "            with open(source_file, 'r') as src:\n",
    "                for line in src.readlines():\n",
    "                    parts = line.strip().split(self._delimiter)\n",
    "                    if len(parts)<3:\n",
    "                        raise ValueError\n",
    "                    key = major_map[int(parts[self._major_ind])]\n",
    "                    value = minor_map[int(parts[self._minor_ind])]\n",
    "                    rating = float(parts[self._r_id])\n",
    "                    if key not in self.data:\n",
    "                        self.data[key] = []\n",
    "                    self.data[key].append((value, rating))\n",
    "                    \n",
    "    def _build_maps(self):\n",
    "        self._user_id_map=dict()\n",
    "        self._item_id_map=dict()\n",
    "        src_files=[path.join(self._data_dir, f)\n",
    "                  for f in listdir(self._data_dir)\n",
    "                  if path.isfile(path.join(self._data_dir, f)) and f.endswith(self._extension)]\n",
    "        \n",
    "        u_id = 0\n",
    "        i_id = 0\n",
    "        for source_file in src_files:\n",
    "            with open(source_file, 'r') as src:\n",
    "                for line in src.readlines():\n",
    "                    parts = line.strip().split(self._delimiter)\n",
    "                    if len(parts)<3:\n",
    "                        raise ValueError\n",
    "                        \n",
    "                    u_id_orig = int(parts[self._u_id])\n",
    "                    if u_id_orig not in self._user_id_map:\n",
    "                        self._user_id_map[u_id_orig] = u_id\n",
    "                        u_id += 1\n",
    "                        \n",
    "                    i_id_orig = int(parts[self._i_id])\n",
    "                    if i_id_orig not in self._item_id_map:\n",
    "                        self._item_id_map[i_id_orig] = i_id\n",
    "                        i_id += 1\n",
    "                        \n",
    "    def iterate_one_epoch(self):\n",
    "        data = self.data\n",
    "        keys = list(data.keys())\n",
    "        shuffle(keys)\n",
    "        s_ind = 0\n",
    "        e_ind = self._batch_size\n",
    "        while e_ind < len(keys):\n",
    "            local_ind=0\n",
    "            inds1=[]\n",
    "            inds2=[]\n",
    "            vals=[]\n",
    "            for ind in range(s_ind, e_ind):\n",
    "                inds2 += [v[0] for v in data[keys[ind]]]\n",
    "                inds1 += [local_ind]*len([v[0] for v in data[keys[ind]]])\n",
    "                vals += [v[1] for v in data[keys[ind]]]\n",
    "                local_ind += 1\n",
    "            i_torch = torch.LongTensor([inds1, inds2])\n",
    "            v_torch = torch.FloatTensor(vals)\n",
    "            mini_batch = torch.sparse.FloatTensor(i_torch, v_torch, torch.Size([self._batch_size, self._vector_dim]))\n",
    "            s_ind += self._batch_size\n",
    "            e_ind += self._batch_size\n",
    "            yield mini_batch\n",
    "            \n",
    "    def iterate_one_epoch_eval(self, for_inf=False):\n",
    "        keys = list(self.data.keys())\n",
    "        s_ind = 0\n",
    "        while s_ind < len(keys):\n",
    "            inds1 = [0] * len([v[0] for v in self.data[keys[s_ind]]])\n",
    "            inds2 = [v[0] for v in self.data[keys[s_ind]]]\n",
    "            vals = [v[1] for v in self.data[keys[s_ind]]]\n",
    "            src_inds1 = [0] * len([v[0] for v in self.src_data[keys[s_ind]]])\n",
    "            src_inds2 = [v[0] for v in self.src_data[keys[s_ind]]]\n",
    "            src_vals = [v[1] for v in self.src_data[keys[s_ind]]]\n",
    "            \n",
    "            i_torch = torch.LongTensor([inds1, inds2])\n",
    "            v_torch = torch.FloatTensor(vals)\n",
    "            src_i_torch = torch.LongTensor([src_inds1, src_inds2])\n",
    "            src_v_torch = torch.FloatTensor(src_vals)\n",
    "            mini_batch = (torch.sparse.FloatTensor(i_torch, v_torch, torch.Size([1, self._vector_dim])),\n",
    "                          torch.sparse.FloatTensor(src_i_torch, src_v_torch, torch.Size([1, self._vector_dim])))\n",
    "            s_ind += 1\n",
    "            if not for_inf:\n",
    "                yield mini_batch\n",
    "            else:\n",
    "                yield mini_batch, keys[s_ind - 1]\n",
    "    @property\n",
    "    def vector_dim(self):\n",
    "        return self._vector_dim\n",
    "    @property\n",
    "    def userIdMap(self):\n",
    "        return self._user_id_map\n",
    "    @property\n",
    "    def itemIdMap(self):\n",
    "        return self._item_id_map\n",
    "    @property\n",
    "    def params(self):\n",
    "        return self._params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4726f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger object\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from io import BytesIO\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, log_dir):\n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "    def scalar_summary(self, tag, value, step):\n",
    "        with self.writer.as_default(step=step):\n",
    "            tf.summary.scalar(name=tag, data=value)\n",
    "    def image_summary(self, tag, images, step):\n",
    "        img_summaries = []\n",
    "        for i, img in enumerate(images):\n",
    "            s = BytesIO()\n",
    "            scipy.misc.toimage(img).save(s, format='png')\n",
    "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
    "                                  height=img.shape[0],\n",
    "                                  width=img.shape[1])\n",
    "            img_summaries.append(tf.Summary.Value(tag='%s/%d' %(tag, i), image=img_sum))\n",
    "        summary = tf.Summary(value=img_summaries)\n",
    "        self.writer.add_summary(summary, step)\n",
    "    def histo_summary(self, tag, values, step, bins=1000):\n",
    "        counts, bin_edges = np.histogram(values, bins=bins)\n",
    "        hist = tf.HistogramProto()\n",
    "        hist.min = float(np.min(values))\n",
    "        hist.max = float(np.max(values))\n",
    "        hist.num = int(np.prod(values.shape))\n",
    "        hist.sum = float(np.sum(values))\n",
    "        hist.sum_squares = float(np.sum(values ** 2))\n",
    "        bin_edges = bin_edges[1:]\n",
    "        for edge in bin_edges:\n",
    "            hist.bucket_limit.append(egde)\n",
    "        for c in counts:\n",
    "            hist.bucket.append(c)\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d45ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(encoder, evaluation_data_layer):\n",
    "    encoder.eval()\n",
    "    denom = 0.0\n",
    "    total_epoch_loss = 0.0\n",
    "    for i, (eval, src) in enumerate(evaluation_data_layer.iterate_one_epoch_eval()):\n",
    "        inputs = Variable(src.cuda().to_dense())\n",
    "        targets = Variable(eval.cuda().to_dense())\n",
    "        outputs = encoder(inputs)\n",
    "        loss, num_ratings = MSEloss(outputs, targets)\n",
    "        total_epoch_loss += loss.item()\n",
    "        denom += num_ratings.item()\n",
    "    return sqrt(total_epoch_loss/ denom)\n",
    "\n",
    "def log_var_and_grad_summaries(logger, layers, global_step, prefix, log_histograms=False):\n",
    "    for ind, w in enumerate(layers):\n",
    "        w_var = w.data.cpu().numpy()\n",
    "        logger.scalar_summary('Variable/FrobNorm/{}_{}'.format(prefix, ind), np.linalg.norm(w_var), global_step)\n",
    "        if log_histograms:\n",
    "            logger.histo_summary(tag='Variables/{}_{}'.format(prefix, ind), values=w.data.cpu().numpy(), step=global_step)\n",
    "        w_grad = w.grad.data.cpu().numpy()\n",
    "        logger.scalar_summary(\"Gradients/FrobNorm/{}_{}\".format(prefix, ind), np.linalg.norm(w_grad), global_step)\n",
    "        if log_histograms:\n",
    "            logger.histo_summary(tag='Gradients/{}_{}'.format(prefix, ind), values=w.grad.data.cpu().numpy(), step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4e6698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified to use DataFrame object as datasource\n",
    "#_____________________________________________________\n",
    "class UserItemRecDataProvider_from_Df(UserItemRecDataProvider):\n",
    "    def __init__(self, params, user_id_map=None, item_id_map=None):\n",
    "        self._params = params\n",
    "        self.DataFrame = params['dataframe']\n",
    "        \n",
    "        self._i_id = 1 if 'itemIdInd' not in self.params else self.params['itemIdInd']\n",
    "        self._u_id = 0 if 'userIdInd' not in self.params else self.params['userIdInd']\n",
    "        self._r_id = 2 if 'ratingInd' not in self.params else self.params['ratingInd']\n",
    "        self._major = 'users' if 'major' not in self.params else self.params['major']\n",
    "        if not (self._major == 'items' or self._major=='users'):\n",
    "            raise ValueError('Major must be \"users\" or \"items\", but got {}'.format(self._major))\n",
    "        self._major_ind = self._i_id if self._major == 'items' else self._u_id\n",
    "        self._minor_ind = self._u_id if self._major == 'items' else self._i_id\n",
    "        if user_id_map is None or item_id_map is None:\n",
    "            self._build_maps()\n",
    "        else:\n",
    "            self._user_id_map = user_id_map\n",
    "            self._item_id_map = item_id_map\n",
    "        major_map = self._item_id_map if self._major=='items' else self._user_id_map\n",
    "        minor_map = self._user_id_map if self._major=='items' else self._item_id_map\n",
    "        self._vector_dim = len(minor_map)\n",
    "        self._batch_size = 32\n",
    "        \n",
    "        self.data = dict()\n",
    "        for idx, row in self.DataFrame.iterrows():\n",
    "            key = major_map[int(row['userId'])]\n",
    "            value = minor_map[int(row['movieId'])]\n",
    "            rating = float(row['rating'])\n",
    "            if key not in self.data:\n",
    "                self.data[key] = []\n",
    "            self.data[key].append((value, rating))\n",
    "                    \n",
    "    def _build_maps(self):\n",
    "        self._user_id_map=dict()\n",
    "        self._item_id_map=dict()\n",
    "       \n",
    "        u_id = 0\n",
    "        i_id = 0\n",
    "        for idx, row in self.DataFrame.iterrows():\n",
    "            u_id_orig = int(row['userId'])\n",
    "            if u_id_orig not in self._user_id_map:\n",
    "                self._user_id_map[u_id_orig] = u_id\n",
    "                u_id += 1\n",
    "            i_id_orig = int(row['movieId'])\n",
    "            if i_id_orig not in self._item_id_map:\n",
    "                self._item_id_map[i_id_orig] = i_id\n",
    "                i_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ce9b7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "# 훈련-검증 데이터셋 분리 \n",
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(dataset, test_size=.3, random_state=42)\n",
    "# 신경망구조 작성\n",
    "params=dict()\n",
    "params['dataframe'] = dataset\n",
    "params['batch_size'] = 64\n",
    "params['major'] = 'users'\n",
    "params['itemIdInd'] = 1\n",
    "params['userIdInd'] = 0\n",
    "\n",
    "hidden_layers='512, 512, 1024'   # [512 - 512 - 1024(latent space) - 512 - 512]\n",
    "drop_prob=0.65                   # dropout rate\n",
    "num_epochs=15\n",
    "non_linearity_type='selu'        # activation function = 'SELU'\n",
    "gpu_ids=1\n",
    "skip_last_layer_nl=True\n",
    "constrained=True\n",
    "summary_frequency = 2000\n",
    "save_every = 3\n",
    "logger = Logger('movielens_logs')\n",
    "logdir = 'movielens_logs'\n",
    "\n",
    "data_layer = UserItemRecDataProvider_from_Df(params=params)\n",
    "print('data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4dc3a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder pass:\n",
      "torch.Size([512, 26744])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from math import sqrt\n",
    "\n",
    "eval_params = copy.deepcopy(params)\n",
    "eval_params['dataframe'] = valid\n",
    "eval_data_layer = UserItemRecDataProvider_from_Df(params = eval_params,\n",
    "                                         user_id_map=data_layer.userIdMap,\n",
    "                                         item_id_map=data_layer.itemIdMap)\n",
    "eval_data_layer.src_data = data_layer.data\n",
    "\n",
    "rencoder = AutoEncoder(layer_sizes=[data_layer.vector_dim] + [int(l) for l in hidden_layers.split(',')],\n",
    "                       nl_type = non_linearity_type,\n",
    "                       is_constrained=constrained,\n",
    "                       dp_drop_prob=drop_prob,\n",
    "                       last_layer_activations=not skip_last_layer_nl)\n",
    "\n",
    "rencoder = rencoder.cuda()\n",
    "optimizer = optim.Adam(rencoder.parameters(),\n",
    "                       lr=0.0001,\n",
    "                       weight_decay=0.0)\n",
    "\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "model_checkpoint = logdir + '/model'\n",
    "path_to_model = Path(model_checkpoint)\n",
    "if path_to_model.is_file():\n",
    "    rencoder.load_state_dict(torch.load(model_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ccb0701",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------epoch 1 of 15-------------\n",
      "0\n",
      "0.0\n",
      "Training_RMSE 0.2809507049071048\n",
      "Training_RMSE 0.07574949932885153\n",
      "Training_RMSE 0.06920665659886573\n",
      "Time consumed :  67.42151618003845\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 2 of 15-------------\n",
      "4327\n",
      "1.4578574448823929\n",
      "Training_RMSE 0.06683862974943665\n",
      "Training_RMSE 0.06733752525466596\n",
      "Training_RMSE 0.06548449864813309\n",
      "Time consumed :  66.31130766868591\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 3 of 15-------------\n",
      "8654\n",
      "1.3917606316972524\n",
      "Training_RMSE 0.06536167993805636\n",
      "Training_RMSE 0.06448217626801031\n",
      "Training_RMSE 0.06519381431950387\n",
      "Time consumed :  67.03990530967712\n",
      "eval_loss  :  0.03407816663722414\n",
      "Saving model to movielens_logs/model.epoch_3\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 4 of 15-------------\n",
      "12981\n",
      "1.3342143872287124\n",
      "Training_RMSE 0.06398366636398493\n",
      "Training_RMSE 0.0634752669527735\n",
      "Training_RMSE 0.06362363893071686\n",
      "Time consumed :  67.37563967704773\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 5 of 15-------------\n",
      "17308\n",
      "1.2842507399618626\n",
      "Training_RMSE 0.06276452295828434\n",
      "Training_RMSE 0.06222861240317238\n",
      "Training_RMSE 0.06230512468218637\n",
      "Time consumed :  67.83569860458374\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 6 of 15-------------\n",
      "21635\n",
      "1.196177379693836\n",
      "Training_RMSE 0.06055816232791925\n",
      "Training_RMSE 0.06044995649452624\n",
      "Training_RMSE 0.060843918699860645\n",
      "Time consumed :  67.72727298736572\n",
      "eval_loss  :  0.03289525870700678\n",
      "Saving model to movielens_logs/model.epoch_6\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 7 of 15-------------\n",
      "25962\n",
      "1.6886219691950828\n",
      "Training_RMSE 0.07194125832180001\n",
      "Training_RMSE 0.060510370365220834\n",
      "Training_RMSE 0.06040154174210446\n",
      "Time consumed :  68.19339108467102\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 8 of 15-------------\n",
      "30289\n",
      "1.187913193483837\n",
      "Training_RMSE 0.06034899013291729\n",
      "Training_RMSE 0.0590727360305906\n",
      "Training_RMSE 0.059841816111420885\n",
      "Time consumed :  67.72566795349121\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 9 of 15-------------\n",
      "34616\n",
      "1.3393858326599002\n",
      "Training_RMSE 0.06407155768009205\n",
      "Training_RMSE 0.059590992460897566\n",
      "Training_RMSE 0.05993513388635098\n",
      "Time consumed :  67.77492570877075\n",
      "eval_loss  :  0.030946952543346985\n",
      "Saving model to movielens_logs/model.epoch_9\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 10 of 15-------------\n",
      "38943\n",
      "1.1105337324552238\n",
      "Training_RMSE 0.058349797185804214\n",
      "Training_RMSE 0.058257111896909686\n",
      "Training_RMSE 0.05841391913732864\n",
      "Time consumed :  66.9961485862732\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 11 of 15-------------\n",
      "43270\n",
      "1.1296495597343892\n",
      "Training_RMSE 0.05891833983258476\n",
      "Training_RMSE 0.05784564786670428\n",
      "Training_RMSE 0.05925767391383277\n",
      "Time consumed :  66.78349471092224\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 12 of 15-------------\n",
      "47597\n",
      "1.1017037867568433\n",
      "Training_RMSE 0.05813055397872684\n",
      "Training_RMSE 0.057388078463955876\n",
      "Training_RMSE 0.05747475663722232\n",
      "Time consumed :  67.315434217453\n",
      "eval_loss  :  0.030580896496235344\n",
      "Saving model to movielens_logs/model.epoch_12\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 13 of 15-------------\n",
      "51924\n",
      "1.1911505041643977\n",
      "Training_RMSE 0.060447123950420525\n",
      "Training_RMSE 0.05702374830086471\n",
      "Training_RMSE 0.05708111284868564\n",
      "Time consumed :  67.4665846824646\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 14 of 15-------------\n",
      "56251\n",
      "1.073169617797248\n",
      "Training_RMSE 0.057397861610262474\n",
      "Training_RMSE 0.056596643717671855\n",
      "Training_RMSE 0.056719382001932654\n",
      "Time consumed :  67.79203701019287\n",
      "eval_loss  :  0.02969003815443311\n",
      "Saving model to movielens_logs/model.epoch_14\n",
      "ONNX model saved to movielens_logs/model.onnx\n",
      "---------------epoch 15 of 15-------------\n",
      "60578\n",
      "1.072123357327655\n",
      "Training_RMSE 0.05739009892809927\n",
      "Training_RMSE 0.055993214387846275\n",
      "Training_RMSE 0.05670577103851497\n",
      "Time consumed :  68.7507553100586\n",
      "eval_loss  :  0.0306149412768587\n",
      "Saving model to movielens_logs/model.epoch_15\n",
      "ONNX model saved to movielens_logs/model.onnx\n"
     ]
    }
   ],
   "source": [
    "loss_list=[]\n",
    "t_loss=0.0\n",
    "t_loss_denom=0.0\n",
    "global_step=0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print(f'---------------epoch {epoch} of {num_epochs}-------------')\n",
    "    print(global_step)\n",
    "    print(t_loss)\n",
    "    e_start_time = time.time()\n",
    "    rencoder.train()\n",
    "    total_epoch_loss = 0.0\n",
    "    denom = 0.0\n",
    "    \n",
    "    for i, mb in enumerate(data_layer.iterate_one_epoch()):\n",
    "        inputs=Variable(mb.cuda().to_dense())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rencoder(inputs)\n",
    "        loss, num_ratings = MSEloss(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "        t_loss += loss.item()\n",
    "        t_loss_denom += 1\n",
    "    \n",
    "        if i%summary_frequency == 0:\n",
    "            logger.scalar_summary(\"Training_RMSE\", sqrt(t_loss/t_loss_denom), global_step)\n",
    "            print('Training_RMSE', sqrt(t_loss/t_loss_denom))\n",
    "            t_loss=0\n",
    "            t_loss_denom=0\n",
    "            log_var_and_grad_summaries(logger, rencoder.encode_w, global_step, \"Encode_W\")\n",
    "            log_var_and_grad_summaries(logger, rencoder.encode_b, global_step, \"Encode_b\")\n",
    "            if not rencoder.is_constrained:\n",
    "                log_var_and_grad_summaries(logger, rencoder.decode_w, global_step, \"Decode_W\")\n",
    "            log_var_and_grad_summaries(logger, rencoder.decode_b, global_step, \"Decode_b\")\n",
    "        total_epoch_loss += loss.item()\n",
    "        denom += 1\n",
    "    loss_list.append(loss.item())\n",
    "    e_end_time = time.time()\n",
    "    logger.scalar_summary(\"Training_RMSE_per_epoch\", sqrt(total_epoch_loss/denom), epoch)\n",
    "    logger.scalar_summary(\"Epoch_time\", e_end_time - e_start_time, epoch)\n",
    "    print('Time consumed : ', e_end_time - e_start_time)\n",
    "    if epoch%save_every==0 or epoch==num_epochs-1:\n",
    "        eval_loss = do_eval(rencoder, eval_data_layer)\n",
    "        print('eval_loss  : ', eval_loss)\n",
    "        logger.scalar_summary(\"EVALUATION_RMSE\", eval_loss, epoch)\n",
    "        print(\"Saving model to {}\".format(model_checkpoint+\".epoch_\"+str(epoch)))\n",
    "        torch.save(rencoder.state_dict(), model_checkpoint+\".epoch_\"+str(epoch))\n",
    "        \n",
    "    torch.save(rencoder.state_dict(), model_checkpoint + '.last')   \n",
    "    dummy_input = Variable(torch.randn(params['batch_size'], data_layer.vector_dim).type(torch.float))\n",
    "    torch.onnx.export(rencoder.float(), dummy_input.cuda(),\n",
    "                       model_checkpoint + '.onnx')\n",
    "    print('ONNX model saved to {}'.format(model_checkpoint + '.onnx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7fde50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder pass:\n",
      "torch.Size([512, 26744])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([1024])\n",
      "Doing : 0\n",
      "Doing : 10000\n",
      "Doing : 20000\n",
      "Doing : 30000\n",
      "Doing : 40000\n",
      "Doing : 50000\n",
      "Doing : 60000\n",
      "Doing : 70000\n",
      "Doing : 80000\n",
      "Doing : 90000\n",
      "Doing : 100000\n",
      "Doing : 110000\n",
      "Doing : 120000\n",
      "Doing : 130000\n"
     ]
    }
   ],
   "source": [
    "#predict for movielens\n",
    "\n",
    "save_path = 'movielens_logs/model.epoch_15'\n",
    "prediction_path = 'out.txt'\n",
    "params = dict()\n",
    "params['batch_size'] = 1\n",
    "params['dataframe'] = dataset\n",
    "params['major'] = 'users'\n",
    "params['itemIdInd'] = 1\n",
    "params['userIdInd'] = 0\n",
    "\n",
    "data_layer = UserItemRecDataProvider_from_Df(params=params)\n",
    "\n",
    "eval_params = copy.deepcopy(params)\n",
    "eval_params['batch_size'] = 1\n",
    "eval_params['dataframe'] = valid\n",
    "eval_data_layer = UserItemRecDataProvider_from_Df(params=eval_params,\n",
    "                                          user_id_map=data_layer.userIdMap,\n",
    "                                          item_id_map=data_layer.itemIdMap)\n",
    "rencoder = AutoEncoder(layer_sizes=[data_layer.vector_dim] + \\\n",
    "                       [int(l) for l in hidden_layers.split(',')],\n",
    "                      nl_type=non_linearity_type,\n",
    "                      is_constrained = constrained,\n",
    "                      dp_drop_prob=drop_prob,\n",
    "                      last_layer_activations=not skip_last_layer_nl)\n",
    "path_to_model = Path(save_path)\n",
    "if path_to_model.is_file():\n",
    "    rencoder.load_state_dict(torch.load(save_path))\n",
    "\n",
    "rencoder.eval()\n",
    "rencoder.cuda()\n",
    "\n",
    "inv_userIdMap = {v: k for k, v in data_layer.userIdMap.items()}\n",
    "inv_itemIdMap = {v: k for k, v in data_layer.itemIdMap.items()}\n",
    "\n",
    "eval_data_layer.src_data = data_layer.data\n",
    "with open(prediction_path, 'w') as outf:\n",
    "    for i, ((out, src), majorInd) in enumerate(eval_data_layer.iterate_one_epoch_eval(for_inf=True)):\n",
    "        inputs = Variable(src.cuda().to_dense())\n",
    "        targets_np = out.to_dense().numpy()[0, :]\n",
    "        outputs = rencoder(inputs).cpu().data.numpy()[0, :]\n",
    "        non_zeros = targets_np.nonzero()[0].tolist()\n",
    "        major_key = inv_userIdMap[majorInd]\n",
    "        for ind in non_zeros:\n",
    "            outf.write('{}\\t{}\\t{}\\t{}\\n'.format(major_key, inv_itemIdMap[ind], outputs[ind], targets_np[ind]))\n",
    "        if i%10000 == 0:\n",
    "            print('Doing : {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7a91a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.8139762648022553\n"
     ]
    }
   ],
   "source": [
    "# computing model prediction score\n",
    "# for movielens\n",
    "\n",
    "with open(prediction_path, 'r') as inpt:\n",
    "    lines = inpt.readlines()\n",
    "    n = 0\n",
    "    denom = 0.0\n",
    "    for line in lines:\n",
    "        parts = line.split('\\t')\n",
    "        prediction = round(float(parts[2]))\n",
    "        rating = float(parts[3])\n",
    "        denom += (prediction - rating)*(prediction - rating)\n",
    "        n += 1\n",
    "    renc_score = sqrt(denom/n)\n",
    "    print(\"RMSE : {}\".format(renc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d512eb7",
   "metadata": {},
   "source": [
    "### 5) Evaluation\n",
    "비교하는 지표로 RMSE를 선정:  \n",
    "평균제곱근편차 Root Mean Squared Error는 모든 오차를 동일한 가중치로 계산  \n",
    "<br>-> 예측과 실제값이 얼마나 가까운지를 나타내는 지표 (낮을수록 성능이 좋다!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b402ae",
   "metadata": {},
   "source": [
    "이 외에도 추천시스템을 평가하는 방식에는 Precision, Recall@k 등 다른 지표들도 활용되고 있습니다.  \n",
    "'개인화' 측면에서는 이런 지표들이 더 성능을 잘 반영할 수 있다고 생각합니다.  \n",
    "<br>\n",
    "아쉽게도 이 프로젝트에서는 시간적 한계로 다른 평가지표들까지 구현하기는 어려웠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01e59467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model   : 0.8587301661401836\n",
      "SVD model   : 0.7929245866825421\n",
      "AutoEncoder : 0.8139762648022553\n"
     ]
    }
   ],
   "source": [
    "# 각 모델의 RMSE\n",
    "print('ALS model   :', als_score)\n",
    "print('SVD model   :', svd_score)\n",
    "print('AutoEncoder :', renc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b3fe1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_output = pd.DataFrame(bsl_predict, \n",
    "                          columns=['userId', 'movieId', 'rating', 'rating_pred', 'state'])\n",
    "als_output = als_output[['userId', 'movieId', 'rating_pred', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c42ab080",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_output = pd.DataFrame(svd_predict, \n",
    "                          columns=['userId', 'movieId', 'rating', 'rating_pred', 'state'])\n",
    "svd_output = svd_output[['userId', 'movieId', 'rating_pred', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56cf7f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000079, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating_pred</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122270</td>\n",
       "      <td>296</td>\n",
       "      <td>4.670368</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122270</td>\n",
       "      <td>593</td>\n",
       "      <td>3.832587</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122270</td>\n",
       "      <td>919</td>\n",
       "      <td>3.761301</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122270</td>\n",
       "      <td>1193</td>\n",
       "      <td>4.010227</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122270</td>\n",
       "      <td>1261</td>\n",
       "      <td>3.416520</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating_pred  rating\n",
       "0  122270      296     4.670368     5.0\n",
       "1  122270      593     3.832587     4.0\n",
       "2  122270      919     3.761301     4.0\n",
       "3  122270     1193     4.010227     5.0\n",
       "4  122270     1261     3.416520     5.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renc_predict = pd.read_csv(prediction_path, delimiter='\\t', header=None,\n",
    "                          names=['userId', 'movieId', 'rating_pred', 'rating'])\n",
    "print(renc_predict.shape)\n",
    "renc_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bea5fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>21</th>\n",
       "      <th>32</th>\n",
       "      <th>34</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>61465</th>\n",
       "      <th>62265</th>\n",
       "      <th>64497</th>\n",
       "      <th>64614</th>\n",
       "      <th>66171</th>\n",
       "      <th>66297</th>\n",
       "      <th>67365</th>\n",
       "      <th>68263</th>\n",
       "      <th>69945</th>\n",
       "      <th>70227</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.626617</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.560899</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.763842</td>\n",
       "      <td>3.602076</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.947162</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.814524</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.197568</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3.67009</td>\n",
       "      <td>3.24434</td>\n",
       "      <td>3.767723</td>\n",
       "      <td>4.271808</td>\n",
       "      <td>3.86959</td>\n",
       "      <td>3.984992</td>\n",
       "      <td>2.979867</td>\n",
       "      <td>4.23512</td>\n",
       "      <td>3.39639</td>\n",
       "      <td>3.484268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.912179</td>\n",
       "      <td></td>\n",
       "      <td>3.669211</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.826863</td>\n",
       "      <td></td>\n",
       "      <td>3.943947</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.712426</td>\n",
       "      <td>3.744217</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.146591</td>\n",
       "      <td>2.998443</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.330819</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId     1         2         6         10        15        17        21     \\\n",
       "userId                                                                          \n",
       "1                                                                               \n",
       "2                                                                               \n",
       "3                                                                               \n",
       "4                                      3.626617                                 \n",
       "5                                                                               \n",
       "6                                                                               \n",
       "7                                                2.763842  3.602076             \n",
       "8                                                                    3.947162   \n",
       "9                                                                               \n",
       "10                                                                              \n",
       "11                                     3.814524                                 \n",
       "12       3.912179            3.669211                      3.826863             \n",
       "13       3.712426  3.744217                                                     \n",
       "14                                                         4.330819             \n",
       "\n",
       "movieId     32        34        39     ...    61465    62265     64497  \\\n",
       "userId                                 ...                               \n",
       "1                                      ...                               \n",
       "2                                      ...                               \n",
       "3                                      ...                               \n",
       "4        3.560899                      ...                               \n",
       "5                                      ...                               \n",
       "6                                      ...                               \n",
       "7                                      ...                               \n",
       "8                                      ...                               \n",
       "9                                      ...                               \n",
       "10                                     ...                               \n",
       "11       4.197568                      ...  3.67009  3.24434  3.767723   \n",
       "12       3.943947                      ...                               \n",
       "13                 3.146591  2.998443  ...                               \n",
       "14                                     ...                               \n",
       "\n",
       "movieId     64614    66171     66297     67365    68263    69945     70227  \n",
       "userId                                                                      \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "5                                                                           \n",
       "6                                                                           \n",
       "7                                                                           \n",
       "8                                                                           \n",
       "9                                                                           \n",
       "10                                                                          \n",
       "11       4.271808  3.86959  3.984992  2.979867  4.23512  3.39639  3.484268  \n",
       "12                                                                          \n",
       "13                                                                          \n",
       "14                                                                          \n",
       "\n",
       "[14 rows x 428 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저-아이템 선호도 테이블\n",
    "pd.pivot_table(svd_output.sort_values(by='userId')[:500],\n",
    "               values='rating_pred', index='userId', columns='movieId').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e477c507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>19</th>\n",
       "      <th>21</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>...</th>\n",
       "      <th>60516</th>\n",
       "      <th>60832</th>\n",
       "      <th>64508</th>\n",
       "      <th>65514</th>\n",
       "      <th>66297</th>\n",
       "      <th>67197</th>\n",
       "      <th>67799</th>\n",
       "      <th>67867</th>\n",
       "      <th>68319</th>\n",
       "      <th>70305</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.29282</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.881709</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.238307</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.506626</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.533792</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.000562</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.768695</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.847795</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.822665</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.528924</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3.85657</td>\n",
       "      <td>4.148592</td>\n",
       "      <td>3.06676</td>\n",
       "      <td>5.063182</td>\n",
       "      <td>4.035837</td>\n",
       "      <td>4.473076</td>\n",
       "      <td>3.132805</td>\n",
       "      <td>2.567681</td>\n",
       "      <td>4.305022</td>\n",
       "      <td>3.762975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.647343</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.375731</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>3.318815</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.186681</td>\n",
       "      <td>3.788532</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.285582</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId     1         2         3         6         10        11        19     \\\n",
       "userId                                                                          \n",
       "1                                                                               \n",
       "2                             4.29282                                           \n",
       "3        3.881709                                                               \n",
       "4                                                                    2.506626   \n",
       "5                                                                               \n",
       "6                                                                               \n",
       "7                                                                               \n",
       "8                            4.000562                                           \n",
       "9                                                                               \n",
       "10                                                         3.847795             \n",
       "11                                               3.528924                       \n",
       "12       3.647343                      3.375731                                 \n",
       "13                 3.318815                      3.186681  3.788532             \n",
       "14       4.285582                                                               \n",
       "\n",
       "movieId     21        24        25     ...    60516     60832    64508  \\\n",
       "userId                                 ...                               \n",
       "1                                      ...                               \n",
       "2                                      ...                               \n",
       "3                  4.238307            ...                               \n",
       "4                                      ...                               \n",
       "5                                      ...                               \n",
       "6                                      ...                               \n",
       "7                  3.533792            ...                               \n",
       "8        3.768695                      ...                               \n",
       "9                                      ...                               \n",
       "10                           3.822665  ...                               \n",
       "11                                     ...  3.85657  4.148592  3.06676   \n",
       "12                                     ...                               \n",
       "13                                     ...                               \n",
       "14                                     ...                               \n",
       "\n",
       "movieId     65514     66297     67197     67799     67867     68319     70305  \n",
       "userId                                                                         \n",
       "1                                                                              \n",
       "2                                                                              \n",
       "3                                                                              \n",
       "4                                                                              \n",
       "5                                                                              \n",
       "6                                                                              \n",
       "7                                                                              \n",
       "8                                                                              \n",
       "9                                                                              \n",
       "10                                                                             \n",
       "11       5.063182  4.035837  4.473076  3.132805  2.567681  4.305022  3.762975  \n",
       "12                                                                             \n",
       "13                                                                             \n",
       "14                                                                             \n",
       "\n",
       "[14 rows x 431 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(renc_predict.sort_values(by='userId')[:500],\n",
    "               values='rating_pred', index='userId', columns='movieId').fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b428d47",
   "metadata": {},
   "source": [
    "### 6) Conclusion\n",
    "RMSE로 측정한 성능 자체에서는 SVD 모델이나 Autoencoder 모델 간의 큰 차이가 보이지 않습니다.  \n",
    "오히려 더 높을 것으로 기대했던 AutoEncoder 모델의 성능이 안좋게 나왔습니다.  \n",
    "더 정밀하게 튜닝을 거친다면 성능의 개선을 이룰 수 있을 것이라 생각합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa66ac",
   "metadata": {},
   "source": [
    "추천 시스템은 개인화 서비스 중 큰 비중을 차지하고 있고 다양한 섹터에서 활용되고 있기 때문에 시스템 성능의 개선은 여러 서비스에 직접적인 영향을 줄 수 있는 요소라고 생각합니다.  \n",
    "<br>딥러닝이라는 기술 자체가 점점 발전되고 고도화되고 있는 만큼 이를 적용해서 추천 시스템을 구현하면 정확도가 높은 모델을 구현할 수 있을 것이라 기대하고 있습니다.  \n",
    "이번 프로젝트에서는 딥러닝 구조를 직접 적용하고 잘 작동하는 것을 확인한 점에서 의미가 있다고 생각합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
